{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.missing_values import extract_subseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holt_smoother(x: np.array, alpha: float) -> np.array:\n",
    "    # https://empslocal.ex.ac.uk/people/staff/dbs202/cag/courses/MT37C/course/node102.html\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "\n",
    "    for t in range(1, len(x)):\n",
    "        y[t] = alpha * x[t] + (1 - alpha) * y[t - 1]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def generate_datetime_ts(ts: TimeSeries) -> TimeSeries:\n",
    "    \"\"\"Generates time series of date time features using one hot encoding\"\"\"\n",
    "    dayofweek = (\n",
    "        pd.get_dummies(ts.time_index.day_of_week)\n",
    "        .rename(columns=lambda x: f\"dow_{x}\")\n",
    "        .set_index(ts.time_index)\n",
    "    )\n",
    "    hours = (\n",
    "        pd.get_dummies(ts.time_index.hour)\n",
    "        .rename(columns=lambda x: f\"hour_{x}\")\n",
    "        .set_index(ts.time_index)\n",
    "    )\n",
    "\n",
    "    datetime_features = dayofweek.merge(\n",
    "        hours, left_index=True, right_index=True\n",
    "    ).astype(int)\n",
    "\n",
    "    return TimeSeries.from_dataframe(datetime_features)\n",
    "\n",
    "\n",
    "def generate_poly_ts(ts: TimeSeries, degree: int) -> TimeSeries:\n",
    "    poly_values = PolynomialFeatures(degree, include_bias=False).fit_transform(\n",
    "        ts.values()\n",
    "    )\n",
    "    poly_features = pd.DataFrame(\n",
    "        poly_values,\n",
    "        columns=[f\"feature_{i}\" for i in range(poly_values.shape[1])],\n",
    "        index=ts.time_index,\n",
    "    )\n",
    "\n",
    "    return TimeSeries.from_dataframe(\n",
    "        poly_features,\n",
    "        freq=\"h\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../processed/data.csv\", index_col=0, parse_dates=True)\n",
    "data.rename(columns={\"FB20F11_81\": \"flow\"}, inplace=True)\n",
    "\n",
    "# These variables have a big gap at the end, so we discard them\n",
    "data.drop(columns=[\"temp_grass\", \"temp_soil_30\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We transform the target and precipitation by computing their logarithm. This step will _squeeze_ their values which can help during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"flow\", \"acc_precip\"]] = data[[\"flow\", \"acc_precip\"]].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For convenience we transform to `TimeSeries`. Then, we extract subseries without gaps and remove subseries that are too short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For later convenience, we will work with darts TimeSeries\n",
    "ts = TimeSeries.from_dataframe(data, freq=\"h\")\n",
    "subseries = extract_subseries(ts, mode=\"any\")\n",
    "\n",
    "min_length = 24 * 7  # 7 days\n",
    "subseries = [s for s in subseries if len(s) >= min_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting subseries between target and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subseries = [s[\"flow\"] for s in subseries]\n",
    "covariates_subseries = [s.drop_columns(\"flow\") for s in subseries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dynamics of observed precipitation are faster than their effects. We smooth the precipitation by using a Holt exponential smoother; the value of the parameter $\\alpha$ is chosen based on the correlation study in the overview [notebook](./overview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "for i, series in enumerate(subseries):\n",
    "    lp_precip = holt_smoother(series[\"acc_precip\"].values().ravel(), alpha)\n",
    "    ts_lp = TimeSeries.from_series(\n",
    "        pd.Series(lp_precip, index=series.time_index, name=\"smooth_precip\")\n",
    "    )\n",
    "    subseries[i] = series.concatenate(ts_lp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We include polynomial functions of the weather features\n",
    "- We include datetime features, using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 3  # polynomial degree\n",
    "poly_covariates = [generate_poly_ts(s, deg) for s in covariates_subseries]\n",
    "datetime_covariates = [generate_datetime_ts(s) for s in covariates_subseries]\n",
    "\n",
    "expanded_covariates = [\n",
    "    plc_i.concatenate(dtc_i, axis=1)\n",
    "    for plc_i, dtc_i in zip(poly_covariates, datetime_covariates)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alt-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
